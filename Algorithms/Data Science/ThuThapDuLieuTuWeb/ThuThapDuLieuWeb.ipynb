{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT01: Thu thập dữ liệu từ web\n",
    "\n",
    "TODO: Võ Phương Hòa - 1412192\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tổng thể\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, mình đã để từ `TODO` để cho biết những chỗ mà bạn cần phải làm. Trong quá trình làm, thường xuyên `Ctrl+S` để lưu lại bài làm.\n",
    "\n",
    "Nên nhớ mục tiêu chính ở đây là *học, học một cách chân thật*. Bạn có thể thảo luận ý tưởng với bạn khác cũng như là tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn, dựa trên sự hiểu của bạn*. Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Trước khi nộp bài, bạn chọn `Kernel` -> `Restart & Run All` (restart python và chạy tất cả các cell), rồi kiểm tra xem có bị lỗi gì không.\n",
    "\n",
    "Sau đó, trong thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) bạn đặt file `BT01-ThuThapDuLieuWeb.ipynb`, rồi nén thư mục `MSSV` này lại và nộp ở link trên moodle.\n",
    "\n",
    "**Nội dung bài tập**\n",
    "\n",
    "Trong bài này, bạn sẽ ôn lại ví dụ \"Nhà Khoa Học Dữ Liệu cần biết ngôn ngữ lập trình nào?\" mà mình đã hướng dẫn ở trên lớp. Cụ thể là bạn sẽ:\n",
    "- Đọc lại phần code mà mình đã hướng dẫn trên lớp.\n",
    "- Bổ sung phần trực quan hóa (visualize) kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests # To read html text\n",
    "from bs4 import BeautifulSoup # To parse html text\n",
    "import re # Regular expressions\n",
    "# You can also import other thing ...\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hàm rút trích tập từ từ một trang web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_word_set(url):\n",
    "    '''\n",
    "    Extracts word set from a web.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The url of the web.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    word_set : set\n",
    "        The set of extracted words.\n",
    "    '''\n",
    "    # Read html text\n",
    "    try:\n",
    "        html_text = requests.get(url).text\n",
    "    except:\n",
    "        print 'Cannot read ' + url\n",
    "        return set([])\n",
    "    \n",
    "    # Parse html text\n",
    "    tree = BeautifulSoup(html_text)\n",
    "    \n",
    "    # Remove invisible tags\n",
    "    for invisible_tag in tree.find_all(['script', 'style']): \n",
    "        invisible_tag.extract()\n",
    "    \n",
    "    # Get texts from visible tags, concatenate them using spaces, and then lower all characters\n",
    "    text = tree.get_text(\" \").lower()\n",
    "    \n",
    "    # Substitute spaces for unwanted things \n",
    "    filtered_text = re.sub(\"[^a-z+#]\", \" \", text)\n",
    "    \n",
    "    # Split filtered text into words, and remove duplicate words\n",
    "    word_set = set(filtered_text.split())\n",
    "\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chương trình chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read html text and parse it\n",
    "url = 'https://www.indeed.com/jobs?q=data+scientist&l='\n",
    "html_text = requests.get(url).text\n",
    "tree = BeautifulSoup(html_text)\n",
    "\n",
    "# Extract num jobs\n",
    "num_jobs = int(tree.find(id='searchCount').string.split()[-1].replace(\",\", \"\"))\n",
    "print 'num_jobs =', num_jobs\n",
    "\n",
    "# Compute num pages\n",
    "num_pages = (num_jobs - 1) / 10 + 1 # 10 jobs / page\n",
    "print 'num_pages =', num_pages\n",
    "num_pages = 50 # It's enough to wait\n",
    "print 'Here we collect first %d pages' %(num_pages)\n",
    "\n",
    "# Init language counts\n",
    "language_counts = {'python': 0, 'r': 0, 'matlab': 0, 'c++': 0, 'c#': 0, 'java': 0}\n",
    "\n",
    "# With each page ...\n",
    "for page_idx in range(num_pages):\n",
    "    print '* Page', page_idx\n",
    "    \n",
    "    # Read html text and parse it\n",
    "    url = 'https://www.indeed.com/jobs?q=data+scientist&start=' + str(page_idx * 10) + '&pp=ABQAAAFakt3ssAAAAAEEW-h_AQEJCAMPSIP4V9-fK7_-Ic_UdBI_lj6hG672oxZDRHZXK26t_QYh9GTXmeLByGiiv7VhGVV8'\n",
    "    html_text = requests.get(url).text\n",
    "    tree = BeautifulSoup(html_text)\n",
    "    \n",
    "    # Find job tags\n",
    "    job_tag_set = tree.find_all(class_='result')\n",
    "    \n",
    "    # With each job tags ...\n",
    "    for job_tag in job_tag_set:\n",
    "        # Extract job url\n",
    "        job_url = 'https://www.indeed.com' + job_tag.find('a')['href']\n",
    "        \n",
    "        # Extract word set from job url\n",
    "        word_set = extract_word_set(job_url)\n",
    "        \n",
    "        # Update language counts\n",
    "        for language in language_counts.keys():\n",
    "            if language in word_set:\n",
    "                language_counts[language] += 1\n",
    "\n",
    "print                \n",
    "print '='*70                \n",
    "print language_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng bar chart để visualize kết quả (trục hoành là ngôn ngữ, trục tung là giá trị đếm; để dễ nhìn, bạn sort các ngôn ngữ theo giá trị đếm giảm dần)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "li_keys = []\n",
    "li_values= []\n",
    "sorted_keys = []\n",
    "sorted_values = []\n",
    "\n",
    "# take keys and values from dict to list\n",
    "for key in language_counts.keys():\n",
    "    li_keys.append(key)\n",
    "for value in language_counts.values():\n",
    "    li_values.append(value)  \n",
    "\n",
    "# sort values from max to min\n",
    "for i in range(len(li_keys)):\n",
    "    value = max(li_values)\n",
    "    ind = li_values.index(value)\n",
    "    sorted_keys.append(li_keys[ind])\n",
    "    sorted_values.append(li_values[ind])\n",
    "    del li_values[ind]\n",
    "    del li_keys[ind]\n",
    "    \n",
    "# draw values by bar chart\n",
    "plt.bar(range(len(sorted_keys)), sorted_values, width = 0.4, tick_label = sorted_keys, align = 'center')\n",
    "plt.axis([-1, len(sorted_keys), 0, int(max(sorted_values) * 1.2)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có nên học python :-)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
