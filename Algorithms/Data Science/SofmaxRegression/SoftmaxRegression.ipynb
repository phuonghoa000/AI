{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT04: Softmax Regression\n",
    "\n",
    "TODO: Võ Phương Hòa - 1412192\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tổng thể\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, mình đã để từ `TODO` để cho biết những chỗ mà bạn cần phải làm (trong đó, `TODO` đầu tiên là bạn phải ghi họ tên và MSSV vào phần đầu của file). Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "Nên nhớ mục tiêu chính ở đây là *học, học một cách chân thật*. Bạn có thể thảo luận ý tưởng với bạn khác cũng như là tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn, dựa trên sự hiểu của bạn*. Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Trước khi nộp bài, bạn chọn `Kernel` -> `Restart & Run All` (restart python và chạy tất cả các cell), rồi kiểm tra xem có bị lỗi gì không.\n",
    "\n",
    "Sau đó, trong thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) bạn đặt file `BT04-SoftmaxRegression.ipynb` (không cần nộp file dữ liệu); rồi nén thư mục `MSSV` này lại và nộp ở link trên moodle.\n",
    "\n",
    "**Nội dung bài tập**\n",
    "\n",
    "Trong bài này, bạn sẽ huấn luyện mô hình Softmax Regression để dự đoán nhãn lớp của ảnh. Bộ dữ liệu được sử dụng là CIFAR-10. Đầu tiên, bạn đọc mô tả về bộ dữ liệu CIFAR-10 [ở đây](https://www.cs.toronto.edu/~kriz/cifar.html). Sau đó, bạn download file dữ liệu `CIFAR-10 python version`, giải nén ra được thư mục `cifar-10-batches-py`, và đặt thư mục này vào cùng thư mục chứa file notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle\n",
    "# You can also import other things ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Định nghĩa các hàm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm đọc bộ dữ liệu CIFAR-10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "def read_data(containing_dir, num_train_batchs):\n",
    "    '''\n",
    "    Read training and test data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    containing_dir : string\n",
    "        The directory containing data files.\n",
    "    num_train_batchs : int\n",
    "        The number of data batchs used for training \n",
    "        (there are totally 5 data batchs; each one contains 10000 images).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (train_X, train_Y, test_X, test Y) : tuple\n",
    "        train_X : numpy array, shape (num_train_batchs*10000, 32x32x3 + 1)\n",
    "            The matrix of input vectors (each row corresponds to an input vector) of the training set;\n",
    "            pixel values are normalized to [0, 1]; \n",
    "            the first column of this matrix is all ones (corresponding to x_0).\n",
    "        train_Y : numpy array, shape (num_train_batchs*10000, 1)\n",
    "            The vector of outputs of the training set.\n",
    "        test_X : numpy array, shape (10000, 32x32x3 + 1)\n",
    "            The matrix of input vectors of the test set (similar to train_X).\n",
    "        test_Y : numpy array, shape (10000, 1)\n",
    "            The vector of outputs of the test set.\n",
    "    '''\n",
    "    # Read training data\n",
    "    train_X_batchs = []\n",
    "    train_Y_batchs = []\n",
    "    for batch_idx in range(num_train_batchs):\n",
    "        batch = unpickle(containing_dir + '\\\\data_batch_' + str(batch_idx + 1))\n",
    "        train_X_batchs.append(batch['data'])\n",
    "        train_Y_batchs.append(np.array(batch['labels']).reshape(-1, 1))\n",
    "    train_X = np.vstack(train_X_batchs)\n",
    "    train_X = train_X / 255. # Normalize to [0, 1]\n",
    "    train_X = np.hstack([np.ones((len(train_X), 1)), train_X])\n",
    "    train_Y = np.vstack(train_Y_batchs)\n",
    "    \n",
    "    # Read test data\n",
    "    batch = unpickle(containing_dir + '\\\\test_batch')\n",
    "    test_X = batch['data']\n",
    "    test_X = test_X / 255. # Normalize to [0, 1]\n",
    "    test_X = np.hstack([np.ones((len(test_X), 1)), test_X])\n",
    "    test_Y = np.array(batch['labels']).reshape(-1, 1)\n",
    "    \n",
    "    return (train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hàm cập nhật lại định dạng của train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_train_Y(Y):\n",
    "    '''\n",
    "    Transfer format for train_Y.\n",
    "    The old format of train_Y is a element is integer number.\n",
    "    But with new format, each element of train_Y is a numpy array\n",
    "    with all of values is zero, escape the value has index is the integer number of old train_Y.\n",
    "    This value is one.\n",
    "    '''\n",
    "    new_Y = np.zeros(shape = (len(Y), len(np.unique(Y))))\n",
    "    for y, new_y in zip(Y, new_Y):\n",
    "        new_y[y[0]] = True\n",
    "        \n",
    "    return new_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm tính output của Softmax Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_softmax_output(W, X):\n",
    "    '''\n",
    "    Computes the outputs of Softmax Regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W : numpy array, shape (d+1, K=10)\n",
    "        The matrix of Softmax Regression's parameters; each column corresponds to parameters of a class.\n",
    "    X : numpy array, shape (N, d+1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones (corresponding to x_0).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A : numpy array, shape (N, K=10)\n",
    "        The maxtrix of Softmax Regression's output vectors; each row is an output vector (containing each \n",
    "        class's probability given the corresponding input vector).\n",
    "    '''\n",
    "    # TODO\n",
    "    # Initialize output A with all of values is 0\n",
    "    A = np.zeros((len(X), W.shape[1]))\n",
    "    \n",
    "    # Output of Softmax Regression\n",
    "    for i in range(len(X)):\n",
    "        A[i] = np.exp(W.T.dot(X[i])) / sum(np.exp(W.T.dot(X[i])))\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm huấn luyện Softmax Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_softmax(X, Y, learning_rate, max_epoch):\n",
    "    '''\n",
    "    Trains Softmax Regression on the dataset (X, Y).\n",
    "    Cost function: mean negative log likelihood.\n",
    "    Optimization algorithm: Gradient Descent.\n",
    "    \n",
    "    Your code also needs to print out the cost and mean binary error on the training set after \n",
    "    each epoch (e.g., 'Epoch ..., cost ..., err ...%').\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones (corresponding to x_0).\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    learning_rate : float\n",
    "        Learning rate of Gradient Descent.\n",
    "    max_epoch : int\n",
    "        After this number of epochs (iterations), we'll terminate Gradient Descent.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (W, costs, errs) : tuple\n",
    "        W : numpy array, shape (d+1, K=10)\n",
    "            The maxtrix of Softmax Regression's parameters after training.\n",
    "        costs : list, len = max_epoch\n",
    "            The list of costs after each epoch.\n",
    "        errs : list, len = max_epoch\n",
    "            The list of mean binary errors (on the training set) after each epoch.\n",
    "    '''\n",
    "    # Init W\n",
    "    K = len(np.unique(Y)) # Num classes\n",
    "    W = np.zeros((X.shape[1], K))\n",
    "    \n",
    "    # TODO\n",
    "    hypothesis = compute_softmax_output(W, X) # hypothesis with initialized W\n",
    "    Y = update_train_Y(Y) # transfer correct output Y into a new format\n",
    "    N = len(X)\n",
    "    costs = []\n",
    "    errs = []\n",
    "    \n",
    "    # training with gradient descent\n",
    "    for e in range(max_epoch):\n",
    "        # Find partial derivatives of E_in with hypothesis\n",
    "        delta_W = X.T.dot(hypothesis - Y) / N\n",
    "        # Update W\n",
    "        W = np.array([w-learning_rate*delta_w for w, delta_w in zip(W, delta_W)])\n",
    "        # Update hypothesis\n",
    "        hypothesis = compute_softmax_output(W, X)\n",
    "        # Find cost value with mean negative log likelihood\n",
    "        cost = sum([-np.log(hy[int(np.argmax(y))]) for hy, y in zip(hypothesis, Y)]) / N\n",
    "        # Find error\n",
    "        err = sum([int(np.argmax(hy)) != int(np.argmax(y)) for y, hy in zip(hypothesis, Y)]) * 100.0 / N\n",
    "        \n",
    "        costs.append(cost)\n",
    "        errs.append(err)\n",
    "        \n",
    "        print 'Epoch #%2d: cost = %.3f, err = %.3f%%' % (e, cost, err)\n",
    "    \n",
    "    return W, costs, errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chạy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Đọc dữ liệu (bạn cần đặt thư mục chứa dữ liệu `cifar-10-batches-py` vào cùng thư mục chứa file notebook này)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape = (30000L, 3073L), train_Y.shape = (30000L, 1L)\n",
      "test_X.shape  = (10000L, 3073L), test_Y.shape  = (10000L, 1L)\n"
     ]
    }
   ],
   "source": [
    "num_train_batchs = 3 # It's enough to make my computer tired\n",
    "train_X, train_Y, test_X, test_Y = read_data('cifar-10-batches-py', num_train_batchs) \n",
    "print 'train_X.shape = %s, train_Y.shape = %s' %(train_X.shape, train_Y.shape)\n",
    "print 'test_X.shape  = %s, test_Y.shape  = %s' %(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Huấn luyện Softmax Regression với các `learning_rate` khác nhau (0.001, 0.01, 0.1) để thấy được ảnh hưởng của `learning_rate` đến quá trình học (ta cố định `max_epoch` bằng 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0: cost = 2.301, err = 90.070%\n",
      "Epoch # 1: cost = 2.300, err = 90.070%\n",
      "Epoch # 2: cost = 2.299, err = 90.073%\n",
      "Epoch # 3: cost = 2.298, err = 90.077%\n",
      "Epoch # 4: cost = 2.297, err = 90.077%\n",
      "Epoch # 5: cost = 2.296, err = 90.083%\n",
      "Epoch # 6: cost = 2.295, err = 90.087%\n",
      "Epoch # 7: cost = 2.294, err = 90.087%\n",
      "Epoch # 8: cost = 2.293, err = 90.090%\n",
      "Epoch # 9: cost = 2.292, err = 90.077%\n",
      "Epoch #10: cost = 2.291, err = 90.083%\n",
      "Epoch #11: cost = 2.290, err = 90.090%\n",
      "Epoch #12: cost = 2.289, err = 90.077%\n",
      "Epoch #13: cost = 2.289, err = 90.067%\n",
      "Epoch #14: cost = 2.288, err = 90.067%\n",
      "Epoch #15: cost = 2.287, err = 90.063%\n",
      "Epoch #16: cost = 2.286, err = 90.023%\n",
      "Epoch #17: cost = 2.285, err = 89.983%\n",
      "Epoch #18: cost = 2.284, err = 89.937%\n",
      "Epoch #19: cost = 2.284, err = 89.883%\n",
      "Epoch #20: cost = 2.283, err = 89.820%\n",
      "Epoch #21: cost = 2.282, err = 89.727%\n",
      "Epoch #22: cost = 2.281, err = 89.637%\n",
      "Epoch #23: cost = 2.280, err = 89.573%\n",
      "Epoch #24: cost = 2.280, err = 89.433%\n",
      "Epoch #25: cost = 2.279, err = 89.367%\n",
      "Epoch #26: cost = 2.278, err = 89.250%\n",
      "Epoch #27: cost = 2.277, err = 89.097%\n",
      "Epoch #28: cost = 2.277, err = 88.967%\n",
      "Epoch #29: cost = 2.276, err = 88.840%\n",
      "Epoch #30: cost = 2.275, err = 88.717%\n",
      "Epoch #31: cost = 2.274, err = 88.497%\n",
      "Epoch #32: cost = 2.274, err = 88.307%\n",
      "Epoch #33: cost = 2.273, err = 88.093%\n",
      "Epoch #34: cost = 2.272, err = 87.917%\n",
      "Epoch #35: cost = 2.271, err = 87.770%\n",
      "Epoch #36: cost = 2.271, err = 87.567%\n",
      "Epoch #37: cost = 2.270, err = 87.357%\n",
      "Epoch #38: cost = 2.269, err = 87.173%\n",
      "Epoch #39: cost = 2.269, err = 86.950%\n",
      "Epoch #40: cost = 2.268, err = 86.787%\n",
      "Epoch #41: cost = 2.267, err = 86.620%\n",
      "Epoch #42: cost = 2.266, err = 86.397%\n",
      "Epoch #43: cost = 2.266, err = 86.187%\n",
      "Epoch #44: cost = 2.265, err = 85.990%\n",
      "Epoch #45: cost = 2.264, err = 85.830%\n",
      "Epoch #46: cost = 2.264, err = 85.627%\n",
      "Epoch #47: cost = 2.263, err = 85.433%\n",
      "Epoch #48: cost = 2.262, err = 85.230%\n",
      "Epoch #49: cost = 2.261, err = 85.013%\n",
      "Epoch #50: cost = 2.261, err = 84.853%\n",
      "Epoch #51: cost = 2.260, err = 84.677%\n",
      "Epoch #52: cost = 2.259, err = 84.557%\n",
      "Epoch #53: cost = 2.259, err = 84.383%\n",
      "Epoch #54: cost = 2.258, err = 84.197%\n",
      "Epoch #55: cost = 2.257, err = 84.043%\n",
      "Epoch #56: cost = 2.257, err = 83.943%\n",
      "Epoch #57: cost = 2.256, err = 83.743%\n",
      "Epoch #58: cost = 2.255, err = 83.573%\n",
      "Epoch #59: cost = 2.255, err = 83.440%\n",
      "Epoch #60: cost = 2.254, err = 83.270%\n",
      "Epoch #61: cost = 2.253, err = 83.117%\n",
      "Epoch #62: cost = 2.252, err = 82.920%\n",
      "Epoch #63: cost = 2.252, err = 82.747%\n",
      "Epoch #64: cost = 2.251, err = 82.620%\n",
      "Epoch #65: cost = 2.250, err = 82.497%\n",
      "Epoch #66: cost = 2.250, err = 82.353%\n",
      "Epoch #67: cost = 2.249, err = 82.200%\n",
      "Epoch #68: cost = 2.249, err = 82.063%\n",
      "Epoch #69: cost = 2.248, err = 81.947%\n",
      "Epoch #70: cost = 2.247, err = 81.857%\n",
      "Epoch #71: cost = 2.247, err = 81.737%\n",
      "Epoch #72: cost = 2.246, err = 81.627%\n",
      "Epoch #73: cost = 2.245, err = 81.450%\n",
      "Epoch #74: cost = 2.245, err = 81.343%\n",
      "Epoch #75: cost = 2.244, err = 81.230%\n",
      "Epoch #76: cost = 2.243, err = 81.153%\n",
      "Epoch #77: cost = 2.243, err = 81.057%\n",
      "Epoch #78: cost = 2.242, err = 80.933%\n",
      "Epoch #79: cost = 2.241, err = 80.823%\n",
      "Epoch #80: cost = 2.241, err = 80.707%\n",
      "Epoch #81: cost = 2.240, err = 80.593%\n",
      "Epoch #82: cost = 2.240, err = 80.517%\n",
      "Epoch #83: cost = 2.239, err = 80.430%\n",
      "Epoch #84: cost = 2.238, err = 80.307%\n",
      "Epoch #85: cost = 2.238, err = 80.210%\n",
      "Epoch #86: cost = 2.237, err = 80.063%\n",
      "Epoch #87: cost = 2.236, err = 79.937%\n",
      "Epoch #88: cost = 2.236, err = 79.853%\n",
      "Epoch #89: cost = 2.235, err = 79.730%\n",
      "Epoch #90: cost = 2.235, err = 79.637%\n",
      "Epoch #91: cost = 2.234, err = 79.567%\n",
      "Epoch #92: cost = 2.233, err = 79.440%\n",
      "Epoch #93: cost = 2.233, err = 79.360%\n",
      "Epoch #94: cost = 2.232, err = 79.267%\n",
      "Epoch #95: cost = 2.232, err = 79.163%\n",
      "Epoch #96: cost = 2.231, err = 79.063%\n",
      "Epoch #97: cost = 2.230, err = 78.977%\n",
      "Epoch #98: cost = 2.230, err = 78.893%\n",
      "Epoch #99: cost = 2.229, err = 78.760%\n"
     ]
    }
   ],
   "source": [
    "W_0, costs_0, errs_0 = train_softmax(train_X, train_Y, 0.001, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy của mình ở epoch cuối (chỉ số epoch tính từ 0): `Epoch 99, cost 2.229, err 78.760%` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0: cost = 2.291, err = 90.070%\n",
      "Epoch # 1: cost = 2.283, err = 90.070%\n",
      "Epoch # 2: cost = 2.276, err = 89.107%\n",
      "Epoch # 3: cost = 2.268, err = 87.110%\n",
      "Epoch # 4: cost = 2.261, err = 85.030%\n",
      "Epoch # 5: cost = 2.254, err = 83.380%\n",
      "Epoch # 6: cost = 2.248, err = 81.910%\n",
      "Epoch # 7: cost = 2.241, err = 80.783%\n",
      "Epoch # 8: cost = 2.235, err = 79.697%\n",
      "Epoch # 9: cost = 2.229, err = 78.687%\n",
      "Epoch #10: cost = 2.223, err = 77.840%\n",
      "Epoch #11: cost = 2.217, err = 77.143%\n",
      "Epoch #12: cost = 2.212, err = 76.527%\n",
      "Epoch #13: cost = 2.206, err = 75.940%\n",
      "Epoch #14: cost = 2.201, err = 75.513%\n",
      "Epoch #15: cost = 2.196, err = 75.037%\n",
      "Epoch #16: cost = 2.191, err = 74.707%\n",
      "Epoch #17: cost = 2.186, err = 74.383%\n",
      "Epoch #18: cost = 2.182, err = 74.090%\n",
      "Epoch #19: cost = 2.177, err = 73.797%\n",
      "Epoch #20: cost = 2.173, err = 73.510%\n",
      "Epoch #21: cost = 2.169, err = 73.307%\n",
      "Epoch #22: cost = 2.164, err = 73.093%\n",
      "Epoch #23: cost = 2.160, err = 72.907%\n",
      "Epoch #24: cost = 2.156, err = 72.680%\n",
      "Epoch #25: cost = 2.153, err = 72.437%\n",
      "Epoch #26: cost = 2.149, err = 72.233%\n",
      "Epoch #27: cost = 2.145, err = 72.050%\n",
      "Epoch #28: cost = 2.142, err = 71.910%\n",
      "Epoch #29: cost = 2.138, err = 71.773%\n",
      "Epoch #30: cost = 2.135, err = 71.633%\n",
      "Epoch #31: cost = 2.131, err = 71.533%\n",
      "Epoch #32: cost = 2.128, err = 71.440%\n",
      "Epoch #33: cost = 2.125, err = 71.320%\n",
      "Epoch #34: cost = 2.122, err = 71.200%\n",
      "Epoch #35: cost = 2.119, err = 71.113%\n",
      "Epoch #36: cost = 2.116, err = 71.033%\n",
      "Epoch #37: cost = 2.113, err = 70.903%\n",
      "Epoch #38: cost = 2.110, err = 70.747%\n",
      "Epoch #39: cost = 2.107, err = 70.663%\n",
      "Epoch #40: cost = 2.105, err = 70.540%\n",
      "Epoch #41: cost = 2.102, err = 70.480%\n",
      "Epoch #42: cost = 2.099, err = 70.390%\n",
      "Epoch #43: cost = 2.097, err = 70.303%\n",
      "Epoch #44: cost = 2.094, err = 70.237%\n",
      "Epoch #45: cost = 2.092, err = 70.130%\n",
      "Epoch #46: cost = 2.090, err = 70.023%\n",
      "Epoch #47: cost = 2.087, err = 69.917%\n",
      "Epoch #48: cost = 2.085, err = 69.853%\n",
      "Epoch #49: cost = 2.083, err = 69.767%\n",
      "Epoch #50: cost = 2.080, err = 69.743%\n",
      "Epoch #51: cost = 2.078, err = 69.630%\n",
      "Epoch #52: cost = 2.076, err = 69.567%\n",
      "Epoch #53: cost = 2.074, err = 69.517%\n",
      "Epoch #54: cost = 2.072, err = 69.420%\n",
      "Epoch #55: cost = 2.070, err = 69.363%\n",
      "Epoch #56: cost = 2.068, err = 69.293%\n",
      "Epoch #57: cost = 2.066, err = 69.260%\n",
      "Epoch #58: cost = 2.064, err = 69.190%\n",
      "Epoch #59: cost = 2.062, err = 69.127%\n",
      "Epoch #60: cost = 2.060, err = 69.073%\n",
      "Epoch #61: cost = 2.058, err = 69.007%\n",
      "Epoch #62: cost = 2.056, err = 68.957%\n",
      "Epoch #63: cost = 2.054, err = 68.900%\n",
      "Epoch #64: cost = 2.053, err = 68.867%\n",
      "Epoch #65: cost = 2.051, err = 68.773%\n",
      "Epoch #66: cost = 2.049, err = 68.743%\n",
      "Epoch #67: cost = 2.047, err = 68.693%\n",
      "Epoch #68: cost = 2.046, err = 68.633%\n",
      "Epoch #69: cost = 2.044, err = 68.597%\n",
      "Epoch #70: cost = 2.043, err = 68.527%\n",
      "Epoch #71: cost = 2.041, err = 68.497%\n",
      "Epoch #72: cost = 2.039, err = 68.440%\n",
      "Epoch #73: cost = 2.038, err = 68.363%\n",
      "Epoch #74: cost = 2.036, err = 68.327%\n",
      "Epoch #75: cost = 2.035, err = 68.260%\n",
      "Epoch #76: cost = 2.033, err = 68.210%\n",
      "Epoch #77: cost = 2.032, err = 68.190%\n",
      "Epoch #78: cost = 2.030, err = 68.143%\n",
      "Epoch #79: cost = 2.029, err = 68.107%\n",
      "Epoch #80: cost = 2.027, err = 68.047%\n",
      "Epoch #81: cost = 2.026, err = 68.013%\n",
      "Epoch #82: cost = 2.025, err = 67.960%\n",
      "Epoch #83: cost = 2.023, err = 67.917%\n",
      "Epoch #84: cost = 2.022, err = 67.887%\n",
      "Epoch #85: cost = 2.021, err = 67.873%\n",
      "Epoch #86: cost = 2.019, err = 67.833%\n",
      "Epoch #87: cost = 2.018, err = 67.810%\n",
      "Epoch #88: cost = 2.017, err = 67.783%\n",
      "Epoch #89: cost = 2.015, err = 67.713%\n",
      "Epoch #90: cost = 2.014, err = 67.683%\n",
      "Epoch #91: cost = 2.013, err = 67.640%\n",
      "Epoch #92: cost = 2.012, err = 67.603%\n",
      "Epoch #93: cost = 2.011, err = 67.577%\n",
      "Epoch #94: cost = 2.009, err = 67.560%\n",
      "Epoch #95: cost = 2.008, err = 67.517%\n",
      "Epoch #96: cost = 2.007, err = 67.467%\n",
      "Epoch #97: cost = 2.006, err = 67.437%\n",
      "Epoch #98: cost = 2.005, err = 67.420%\n",
      "Epoch #99: cost = 2.004, err = 67.357%\n"
     ]
    }
   ],
   "source": [
    "W_1, costs_1, errs_1 = train_softmax(train_X, train_Y, 0.01, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy của mình ở epoch cuối (chỉ số epoch tính từ 0): `Epoch 99, cost 2.004, err 67.357%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0: cost = 2.374, err = 90.070%\n",
      "Epoch # 1: cost = 4.360, err = 89.693%\n",
      "Epoch # 2: cost = 6.202, err = 89.280%\n",
      "Epoch # 3: cost = 7.979, err = 89.103%\n",
      "Epoch # 4: cost = 10.392, err = 88.223%\n",
      "Epoch # 5: cost = 13.307, err = 82.627%\n",
      "Epoch # 6: cost = 15.558, err = 87.637%\n",
      "Epoch # 7: cost = 15.313, err = 90.153%\n",
      "Epoch # 8: cost = 15.679, err = 86.740%\n",
      "Epoch # 9: cost = 15.290, err = 85.753%\n",
      "Epoch #10: cost = 17.912, err = 86.357%\n",
      "Epoch #11: cost = 16.445, err = 89.703%\n",
      "Epoch #12: cost = 17.385, err = 89.767%\n",
      "Epoch #13: cost = 17.520, err = 89.057%\n",
      "Epoch #14: cost = 18.236, err = 84.720%\n",
      "Epoch #15: cost = 19.514, err = 80.167%\n",
      "Epoch #16: cost = 14.624, err = 88.920%\n",
      "Epoch #17: cost = 12.020, err = 84.143%\n",
      "Epoch #18: cost = 13.295, err = 83.793%\n",
      "Epoch #19: cost = 13.647, err = 84.970%\n",
      "Epoch #20: cost = 15.551, err = 84.333%\n",
      "Epoch #21: cost = 14.438, err = 85.417%\n",
      "Epoch #22: cost = 15.938, err = 84.620%\n",
      "Epoch #23: cost = 15.662, err = 89.613%\n",
      "Epoch #24: cost = 13.317, err = 90.210%\n",
      "Epoch #25: cost = 14.283, err = 85.340%\n",
      "Epoch #26: cost = 15.723, err = 86.170%\n",
      "Epoch #27: cost = 16.718, err = 89.207%\n",
      "Epoch #28: cost = 18.572, err = 80.443%\n",
      "Epoch #29: cost = 17.529, err = 83.710%\n",
      "Epoch #30: cost = 14.417, err = 89.843%\n",
      "Epoch #31: cost = 14.868, err = 86.810%\n",
      "Epoch #32: cost = 16.968, err = 79.683%\n",
      "Epoch #33: cost = 17.994, err = 86.367%\n",
      "Epoch #34: cost = 17.346, err = 81.270%\n",
      "Epoch #35: cost = 16.284, err = 83.937%\n",
      "Epoch #36: cost = 16.235, err = 80.417%\n",
      "Epoch #37: cost = 14.320, err = 89.080%\n",
      "Epoch #38: cost = 14.865, err = 88.673%\n",
      "Epoch #39: cost = 15.344, err = 86.293%\n",
      "Epoch #40: cost = 15.724, err = 77.067%\n",
      "Epoch #41: cost = 16.264, err = 86.260%\n",
      "Epoch #42: cost = 16.741, err = 81.933%\n",
      "Epoch #43: cost = 16.567, err = 89.220%\n",
      "Epoch #44: cost = 16.622, err = 81.563%\n",
      "Epoch #45: cost = 16.765, err = 86.147%\n",
      "Epoch #46: cost = 16.902, err = 80.930%\n",
      "Epoch #47: cost = 17.669, err = 89.563%\n",
      "Epoch #48: cost = 18.023, err = 86.457%\n",
      "Epoch #49: cost = 16.848, err = 80.057%\n",
      "Epoch #50: cost = 15.047, err = 90.170%\n",
      "Epoch #51: cost = 14.057, err = 84.773%\n",
      "Epoch #52: cost = 13.235, err = 80.860%\n",
      "Epoch #53: cost = 14.185, err = 79.133%\n",
      "Epoch #54: cost = 13.218, err = 84.820%\n",
      "Epoch #55: cost = 13.715, err = 84.813%\n",
      "Epoch #56: cost = 13.376, err = 84.610%\n",
      "Epoch #57: cost = 14.753, err = 83.807%\n",
      "Epoch #58: cost = 13.986, err = 82.327%\n",
      "Epoch #59: cost = 12.898, err = 79.140%\n",
      "Epoch #60: cost = 11.201, err = 88.887%\n",
      "Epoch #61: cost = 11.175, err = 81.257%\n",
      "Epoch #62: cost = 9.604, err = 77.317%\n",
      "Epoch #63: cost = 9.630, err = 80.483%\n",
      "Epoch #64: cost = 11.517, err = 78.047%\n",
      "Epoch #65: cost = 10.406, err = 84.960%\n",
      "Epoch #66: cost = 11.129, err = 77.607%\n",
      "Epoch #67: cost = 11.599, err = 81.873%\n",
      "Epoch #68: cost = 11.984, err = 81.023%\n",
      "Epoch #69: cost = 13.024, err = 82.687%\n",
      "Epoch #70: cost = 11.744, err = 83.063%\n",
      "Epoch #71: cost = 10.215, err = 80.903%\n",
      "Epoch #72: cost = 9.574, err = 79.023%\n",
      "Epoch #73: cost = 10.575, err = 81.433%\n",
      "Epoch #74: cost = 11.838, err = 76.467%\n",
      "Epoch #75: cost = 8.169, err = 86.523%\n",
      "Epoch #76: cost = 9.088, err = 77.933%\n",
      "Epoch #77: cost = 10.814, err = 79.467%\n",
      "Epoch #78: cost = 10.574, err = 75.263%\n",
      "Epoch #79: cost = 9.719, err = 84.767%\n",
      "Epoch #80: cost = 10.948, err = 76.713%\n",
      "Epoch #81: cost = 11.045, err = 78.283%\n",
      "Epoch #82: cost = 8.230, err = 82.510%\n",
      "Epoch #83: cost = 9.506, err = 78.223%\n",
      "Epoch #84: cost = 11.391, err = 79.707%\n",
      "Epoch #85: cost = 8.231, err = 79.293%\n",
      "Epoch #86: cost = 7.203, err = 74.487%\n",
      "Epoch #87: cost = 7.118, err = 78.947%\n",
      "Epoch #88: cost = 9.451, err = 74.203%\n",
      "Epoch #89: cost = 7.680, err = 84.957%\n",
      "Epoch #90: cost = 9.481, err = 81.733%\n",
      "Epoch #91: cost = 10.735, err = 80.707%\n",
      "Epoch #92: cost = 11.722, err = 82.317%\n",
      "Epoch #93: cost = 12.038, err = 88.677%\n",
      "Epoch #94: cost = 11.392, err = 77.203%\n",
      "Epoch #95: cost = 11.849, err = 76.430%\n",
      "Epoch #96: cost = 8.549, err = 79.627%\n",
      "Epoch #97: cost = 9.947, err = 73.487%\n",
      "Epoch #98: cost = 9.935, err = 81.010%\n",
      "Epoch #99: cost = 10.590, err = 83.353%\n"
     ]
    }
   ],
   "source": [
    "W_2, costs_2, errs_2 = train_softmax(train_X, train_Y, 0.1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy của mình ở epoch cuối (chỉ số epoch tính từ 0): `Epoch 99, cost 10.076, err 83.273%`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7330cc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXl4FFXWxt/TZIFANhL2fVEWkU1HluDAwLgiMoILyq6j\nIvrJoOOoOIKM4zio444o6iARcUEUQVERMIiIoCKIyKgkyBYIBBISsqdzvj9Od6e7092pTnrP+T1P\nPV3LrVu3ilBv3XPuPYeYGYqiKIriClOwG6AoiqKELioSiqIoiltUJBRFURS3qEgoiqIoblGRUBRF\nUdyiIqEoiqK4xa8iQUSxRLSNiL4not1ENM9NuWeJ6Fci2klE/f3ZJkVRFMU4Uf6snJnLiOgPzFxM\nRI0AbCGij5l5u7UMEV0GoBszn0VEgwC8CGCwP9ulKIqiGMPv5iZmLrasxkJEyXn23lgA6Zay2wAk\nElErf7dLURRFqR2/iwQRmYjoewDHAHzGzN84FWkH4JDd9hHLPkVRFCXIBKInUcXMAwC0BzCIiHr7\n+5qKoiiKb/CrT8IeZi4gos8BXArgJ7tDRwB0sNtub9nnABFpkClFUZQ6wMxU13P9PboplYgSLetN\nAFwE4H9OxVYDmGIpMxhAPjPnuKqPmcN7qaoC//xzveuZN29e8O8lRBZ9Fvos9Fl4XuqLv81NbQB8\nTkQ7AWwD8CkzryWiW4noFgBg5rUA9hPRPgAvAZjp5zYFj3ffBQYMAHzwD6coihII/D0EdjeAgS72\nv+S0fYc/2xESlJUB990HlJcDOTlA69bBbpGiKEqtBMwn0eB54QWgVy8gNRXYv79eIjFixAjftSvM\n0WdRjT6LavRZ+A7yhc0qEBARh0tba5CXB/ToAWRkAP/4BzBmDDBxYrBbpShKA4CIwKHquFYsPPII\nMG4c0Ls30LWr9CTCgQULgOeeC3YrFEUJImpu8jdZWcBrrwE//ijbXboAX38d1CYZwmwGnn4aKC0F\nLroI6Nkz2C1SFCUIaE/Cn+TlSQ9izpxqH0SXLiIcoc7GjUD79sA//wncdBNQVVW3eiorfduuYJGT\nAxQX115OUSIMFQlvePZZeVkYoagIGD0aGDECmD27en+XLuFhblq2TPwmt90GEInj3Vvy8oDOnYGH\nH/Z58wJGbi5w991yH3/5S7BboygBR0XCKGVlwN/+JkJhpOy4ceKsfvJJecla6dgROHoUqKjwX1vr\nS3ExsHo1MGECYDIBr74KPPQQ8Ntv3tXzt7+JSL71FvDgg+E1P4QZePRRMbOVlgI7dgAffFBtNlSU\nBoKKhFG+/RZo0QJ4+WXXZoeCAuDzz4HHHgNGjQKaNZOyJqdHHB0NtGkDHDpUs45QYc0a4IILqk1k\nPXrI1/RddxmvIyMD+OQT6YF8/rm8YO+/P3yE4pFHgJUrge3bgYULZfjyAw+I8ClKA0JFwiibNwPj\nxwNDhogpxp5Nm8R+//e/A9nZwMyZwPLlQJSbcQGh7pewmprsuflm8VMYecmXlAC33AI8/zyQkAC0\nbClCsW4d8O9/+6fNvuSdd0Tg16yR0WhWZswA9u0DPvsseG1TlEAT7LgiXsQf4aBy+eXM777LvHEj\nc69ezFVVsr+wkLlLF+Y1a4zXNX068+LF/mlnfTlxgjkhgbmgoOax9u2ZMzNrr2POHOarr665/+BB\n5pQUY3UEi6+/Zm7RgnnnTtfH33uPuW9f5srKwLZLUeqI5d1Z53ev9iSMUFUFfPUVMGyY2Nijo+Wr\nGBDzw/DhwBVXGK8vlOdKrFgBXHYZEB9f89iAAWKb98RvvwGLF7v23XToICYrb8xWgYAZyMwE3nhD\nfEmvvgr06+e67J/+JL2jpUsD20ZFCRI6T8IIP/4o/ohWloR5s2fLHIJGjYAPPwR++MG7+rp0EVNG\nqMEMvP66DNl1xcCBwPffA1df7b6ONWtkRnmbNq6P33030KcP8PHHIkb+oLJSBgxUVQGXXCIvfHvf\nUHEx8M03IvxffSXzVho3BgYNAp55RtrvDiJxaN90EzB9uuOgBEWJQLQnYYTNm4ELL6zenjBBXpaT\nJontOinJu/pCdRjsBx8Ap07Ji9UVAwbIfXvik088v/xjY0VgZ82SUWC+5tgxmfz32WfiH7ruOqBt\nW+kBnnOOxM5KTpYe4IkTwJQpck+HDkmUXk8CaCUtTdq+e7fv268oIYbGbjLChAnApZcC06ZV73vq\nKeDwYeA///G+vqNH5ev2+HGfNbHeFBVJ2JAlS4CRI12XOXhQvraPHnV9vLRUnNQHD9YunGPGSM/k\njjuA5s2lV1ZfNm8Grr9evvLnzq2uc/9+GSjQsqUsqan1v95f/wo0aRLec0CUBkF9YzepSNQGs4xc\n2rQJ6N7dd3U2bSoi0ayZb+qsL/fdJ1/Tb7zhvgyzvGD37HEdxfbTT+Wl+eWXtV8vM1Ps/4cPA6dP\ny8v700+Bc8+tW/vT04F77pEQKP4yY9mzbRswdSqwd6+anJSQRgP8+ZvffhPbdrduvquTSGbw+trk\ndPQokJ/v/Xl79oiztrZeEZFnk1NtpiZ7unUDdu0CTp6UHsgNNwBvv+1duwERrgULpOeQkREYgQBk\nHklJiU6uUyIeFYnasPojfP216A+/xLhxQKdOYm/PzjZ2DrPM65g3z1iOC08iUVdndFQUcNVV3jvz\nq6okVMayZcCWLTLhLVAQif/i3XcDd01FCQINVyRcOU0LCmT0zZw58pUIiOlk2DDfX78+w2BdBdvb\nu1d6PTt2yL316QM88UTtdX34oZh7brvN2LXdDYPdv19iNfXvb6weZwYPFmE7eNBY+awscVDv2iVC\n3q5d3a5bH665RoYMK0oE0zBFYssWIDFRHNHffiv73n9fRr+cPi328gEDZGik88gmX1HXWdfvvCOB\nA51ZskRG6nTrJsM4N20ylgti8WIZaWTUkeuuJ/HJJ+Lcdw5DYpRGjaQX8uGHnstZQ5hfcIGUX7/e\n+9FlvmLQIODMGTHXKUqE0jDnSWzYIC/U7t3FZGAyATEx4rT9/e+lzIoVMnGqpATo29f3bejSRWzo\n3vLuuzKR7/PPgT/8QfZVVsr8hs8/ry7Xp4/MBzh8WBzvrjhyRHpKb75p/Ppnny2RcE+fFqG18vHH\n4leoD2PGiNjNnOn6eG6uhEYBgK1bgbPOqt/16ovV5LRihXxgKEokUp/p2oFc4MuwHKNGVYfRqKxk\n3rKFubS0ZrmcHOaPP/bdde35/nvmPn28O6eigjkpifmxx5gvvLA6NMiaNcyDB9csP3Ys81tvua/v\nkUeYb7nFuzYwMw8ZwpyRUb1dWiqhPHJzva/Lnvx85vh45jNnah776Sfmrl0l5IfZXL/r+JKvvmLu\n3TvYrVAUt0DDcnhJRYUMX0xLk+1GjYChQ2WSlzMtW4oJxR9YHdfeDOvdulV8GbNny9f8xo2yf8kS\nmf3rTFqamNZcUVUlI5r+/Gfv2+5scvryS5ljkZLifV32JCaKGWn9esf9n30mk+HmzZPorHU1afmD\nQYOkx7Z5c7Bboih+IYT+twWI77+XF21ycnDbkZgownTihPFz1q4VO3xUlAz5nDdPTDAbNsjMYmc8\niURGhszROP9879tuLxI5ORJCe9w47+txxRVXOI5yWrECmDxZfqdM8c01fInJBPzjHzJHwx/zeI4f\nD+2w8krE0/BE4osv/OOIrgveOq/XrgUuv1zWJ0yQOQY33SQvVnv/gJXzzgN+/lmcq8688oqcW5eh\nvdYRTjt2yJf/pZfKqDBfMGYM8NFH0tN55x3gzjvFB2P1FYUiEycC5eX+Gel0990yA97Vv6GiBIL6\n2KoCucBXPokrr/Rspw8kkyYxv/KKsbKHDzM3b+4YovrNN5kB5vXr3Z+Xllbz+MmTzImJ8lsXSkuZ\nGzdmTk1lXrGibnV4omdP5nvvZW7dmnnXLt/X7w/WrxefiSvfVl3Jz5d/pz/9qW6+I0Vh9Ul4R1WV\n2M9DpSdhJGCelY8/lnkB9kNVr70WWLSoepSTK4YNqxkmY9ky6ZE0b+59mwExk917r/gKjATE85Yx\nY8Rf8umn/hlZ5g9GjZIMfosW+a7Ot98G/vhHCUu+bl1oRg5WIp/6KEwgF/iiJ7F7N3O3bvWvx1ds\n3Mg8dKixsuPGMS9d6v01Vq9mvuii6u3iYuYOHZi3bvW+rkCRn8986FCwW+E9u3dLwqK8vJrHKiqY\nr7mG+ZdfjNc3aBDzRx/J+hdfSM/q2DHftFVpMEB7El6weXNo2bb795dcFK5mUNtTXi7OaXchvD0x\ndKiM5jKbZXvhQvFVDB7sfV2BIjHR/dyOUKZPH2DsWOChh2oeW7pUfC1//7uxuvbsEYf1xRfL9oUX\nAjfeKGlhFSWANCyRCCWnNSAjrFJTJW+yJ776SiaOWZMeeUNKiuRT2L1bgv899hjwr3/Vrb1K7Tz6\nqExOtA9dUlwsI9HWrJEPle++q72eJUskyqx9nvR584CdOyVhkqIEiIYjEsyh15MAjPklVq2qX3RT\n61DYxx4Te38gA+E1NFJTJSrtrbdW996efVZ6biNHAg8+WDPz3+efSy9x507ZrqiQGfTOc19iYiT1\n62OP+f8+FMVCwxGJ/fvFrNO1a7Bb4ognkSgqAmbMEJGYOrXu1xg2DFi5EnjpJdemEMW3TJ0q+UJe\neEGGKT/xRHXv7c9/lthg1omQ69fLHJfBg8W0NH++/Hv36OE67MhNN8kcl19/DdjtKA2bhiMS1l5E\nqCWIcScS27bJsZISiXRan3wWaWnytXrjjUCHDnWvRzEGEfDii/LCv/NOiRZ79tlyLDpaEjPdf78E\nRbzhBhHw+fPl72D7dsmud+ONrutu1kwi9tYlI6Ki1IGGk5lu5kz5Ops1y3eN8gVHjogY5ORUC9iR\nI5KhbfFi3wwxZRaH54IFdR/2qnjP3LnAk0+Kz8k+V0dVlaRuPXBAnNlDh1YfY5ahxcOHuw4VA8gs\n7J49gZ9+MpYDRGnQaPpSo4wcKV9vF13ku0b5AmZxSH//fXVOhAUL5MXy8svBbZtSP8rLgV9+kVFP\nzvz0k/gs6pqu9fbbZRRYsAchVFXJgAj9+AhZNH2pUX7+WXoSoYZzSlBmydM8bVowW6X4gpgY1wIB\nSEDEugoEIOE6Fi+WRFnB5LnnJPhimHxsKt7TMESisFCypoXq2Ht7kfjmG8kPYW+CUBRnunYVZ/fa\ntcFrQ2Ul8NRTYjbbtSt47VD8il9FgojaE9FGItpDRLuJ6E4XZYYTUT4R7bAsBmcbecGvv8pIkVAK\nMW1P//7VIrF0qUQ7DTUHuxJ6XHKJTLIMFitXAh07AnfcIUN2lYjE32/NSgB3MfM5AIYAuJ2Ieroo\n9wUzD7Qs//R5K0LV1GTF2pMoKwPeektCYytKbfzxj+LkDoaph1lGWN19NzBpkkwgtM4LUSIKv4oE\nMx9j5p2W9TMA9gJwlbHev5/NoS4SZ50leSFefx3o1w/o3DnYLVLCgZ49ZeJdZmbgr715szisrZMz\n27YNbq9G8RsBs78QUWcA/QFsc3F4CBHtJKKPiKi3zy8e6iJhMkm00wcfrN+kOaVhQSS9CedMfoHg\nP/+R2d9WE+7kyWpyilCiai9Sf4ioGYB3Acyy9Cjs+Q5AR2YuJqLLAKwCcLareh6ymy08YsQIjBgx\nwlgDfv5ZUn6GMgMGiPNv/Phgt0QJJ/74R+CDD2RmfqD4+WdJpfvmm9X7rr9eYkudOSMT/hTj5OTU\nLS6bGzIyMpCRkeGz+vw+T4KIogB8COBjZn7GQPn9AM5j5lNO++s2T4IZiI+XCWqusreFCu+/L134\nJ58MdkuUcCI7W4bZnjjhmGvEX5SVyQzyAQNklrg9o0dLxkT1qRmjtFTmbj39NLB6tZju/EA4zJP4\nL4Cf3AkEEbWyW78AIlynXJWtE9nZ8mUTygIBAFddpQKheE/btkCbNsaTV9WHvDwZURUdDdx3X83j\nkydLQitvWbkS2LSp/u0LJ378UVL/HjoksbpmzJA4X/Zs3CghXIKMv4fApgGYCGAkEX1vGeJ6KRHd\nSkTWwPhXE9GPRPQ9gKcBXOfTRoS6P0JR6ksg/BK//SYxwAYOlNzjTZrULHPllRJz7MQJ7+p++GHJ\nQthQ+PprySb5l79IXvSxY6UHNnNmdZktW+TDMRT8PPXJWBTIBXXNTPfCC8w331y3cxUlHFi9mnnU\nqLqd+9tvtZf55Rfmtm2Zn3mm9rJXXCG5143yyy/MAPPUqcbPCXeuukreS/YUF0tu97feYv72W8lw\nuHKl5JKvqqrX5aCZ6WpBexJKpDN8uHzBl5R4d96xYxJd+PBh92WOHhUT07x5EtG2Ni66SOZuGGXF\nChkCnp1t/Bx/8dtv/r/GgQNiWnP22zRpIhNp77xTfDsvvQSMGwfExcnw+CDSMETibJeDpRQlMkhI\nkCHUW7Z4d94338gEuDfecH389GlJdjV9uvG0qVaRMDrIZMUK4P/+L/gikZUlAwD8PTFx0SKJqOBq\nBNgFF0i+l+efF1MTIDPaDx70b5tqoWGIhPYklEjn4oslPMb48ZKY6Nlnaz9n+3axjS9dWvPlWFoK\n/OlPkrDKaF5uQCb4VVUZS4q0b5/0VK67Tn6DyfbtkuTLn1/tJSXAq69KBF933HabY3qADh3EuR1E\nIlskysrkC6VLl2C3RFH8y333yRfoDTdIcMi5cyXvhCe2bxfnaVkZ8O23jsceeUR6KM88410cMSLj\nJqcVK0TUWrSQ+RWlpcavY4Tjx2VouRHnrzVvuD9fyMuXS2+he3fj53TooD0Jv7Jvn4S4iI4OdksU\nxb/ExsooJ2tPIi0N+OIL9+WZ5cV4wQVi/khPrz52+LCkXn3++brNvfBGJK65RoSlTRvf9SbWrZMe\nzdlnS4bAGTNqNyN9842Ior9eyMwSVv3//s+78zp21J6EX1FTk9JQGTHC89yDzEyxi7duLSLx1luS\nJAkAHnhAXqx1TXU7apTk4a6sdF9m3z7p5V94oWy3bVu7X+KLL8RcU1sgwaeekh7SyZMytDY21rMZ\nyWyWeSajR/vvhfzll0BxsZgFvUHNTX5GndZKQ2X4cM8isX279CIAMcf27i25KXbskC/xe++t+7Vb\ntQI6dZJruGPFChm9Y+2pGBGJRYskvtmgQe7rPn1aHPgTJ1bX3aULsH+/+3r37pWeTL9+/utJLF4s\nvghv0xWoucnPaE9CaagMHChDOt19QX/zDfC731VvT5kiDuy//lWGuyYk1O/6tZmcVqwArr22etuI\nSGzbJpFmZ80Sp/pf/1qzzMcfA7//vYTisVKbSFifhb++2isqJJd5XfLVe2tuqqqS6/hwOK+KhKJE\nIlFR4pfYvNn1cfueBCC+gXXrJNjcn/9c/+tfdJH7WeA//iizsq2mJqB2kTh+XMKC9Oghcwz27pWh\nuz/+6Fju/fdFQOzp3NnzS9MqEv4abrpli2QSbOcqS0IttG0r/yaeTHf2pKeLT6ljR++v5YbIFolf\nflFzk9JwGT5cfAPOVFRIxOHzzqvel5AgJqaFC0Vg6suFFwI7d0rqYGdee016LvZO8doc19u2yYvc\naq5JTBTzzdNPV5cpKxMfxJVXOp5bW09i+3b/9iTWrKl78L7oaKBlS2PzSE6floCBzz3n0yyckSsS\np06J+rZsGeyWKEpwcOeX2LNHvjSdTUpz54rD2xfExUlPZeNGx/0VFRIE0DlvSm09iW3bJKe3PTNm\nSHDAnBzZ3rABOPfcmv/nO3d2LxJlZcBPP0lUW+tXe0VFrbdnGOb6R3g1Kl4PPwxcfrmjGdEHRK5I\nZGbKeGTNFa00VM4/X2YSn3IKquxsavIX06fLfIuqqup9n3wioUCce/hGRGLQIMd9qani11i0SLZX\nraqeqWxPly7uzU27dklYkLg4+Wpv1cq3s79//lkm0Q0YUPc6jDiv9+4Vn9Kjj9b9Om6IXJH49Vfv\nJq0oSqQRHS1f385+iUCJxA03iNnDfjLbkiUiHs54EomqKvdt/stfRCSKiiT5krM/ApCexIEDjmJl\nxdmB72uTk9XUVJ+PVVfO66IiGUZ86JD4d/7yFxm67AfLSeSKxL59KhKK4srk5Pxi9Bcmk8zYnjNH\nfBMnToj5yX5Uk5WkJDH9FBXVPPa//0mvoUWLmsd69ZIe0x13yJyPrl1rlomLEx/GsWM1j1knFFrx\ntfO6Pv4IK656EnffLQMThgyR4ctFRZ7DfdSDyBaJs84KdisUJbg4T6orKpJedt++gbn+oEEy0ulf\n/5KwFGPGuB5eSyS9CVfOa1emJntmzxZnuCtTkxV3zmt/9iROnhRz1siR9avHVZs2bpTRaIcPi/h+\n+aXfIksEJMd1UPj1V+ORKxUlUvnd72SUX2amOGS3bBHnbmxs4Nrw6KNyzcREmVTmDqvJydkC4Mpp\nbc+oUSIQEya4L2MVibS06n2FheKr6NOnel/HjtJz8QVr14pANG5cv3qczU1Hj8r8l3PPrV+9Bons\nnoSam5SGTkyMhIIYNEiGhr7yCnDjjYFtQ5s2MvHNbJaos57KufJLfP21554EEfDeexKvyR2u5krs\n2CE9KvsvcF/2JHxhagJqmps2bZIJgz4c5uqJyOxJ5OdLRMlWrWovqyiRzsqVwW4BcM89wLRpnl9s\nrsxNVvNY//71u36XLtIjsceV+Hjrk3j/fWmbc6Rps1nmbDz3XN3aa481Sm5xsfhXMjLE1xQgIrMn\nYe1F6PBXRQkNGjUSx7InXI1w+u47MQfV1zzmaq7Exo01ezbe9iSefFJGVTmTmQk0b+6bD1WTCWjf\nvrpdmzb5bj6LkcsH7EqBRE1NihJ+uBKJ2kxNRnGeK1FWBmzdWvOLPDVVvtjPnDFWb1YW8MMPNffv\n3u3bwQFW8Tp2TJZADTxAJIuEjmxSlPDClUjU5rQ2SseOwJEj1TGQtm0TH0ZSkmM5IuNB9UpKpL27\ndtU89sMPvnUsW9v0xReSLbAueT7qSGSKhE6kU5Tww1kkKitlIuDQofWvOzZWbPuHD8v2hg0yKsoV\nRk1OBw5Im/furRmA74cffN+TOHgw4KYmIFJFQs1NihJ+OI9u2rhRfAmdO/umfnuT04YN7ucvGHVe\nZ2WJv6Rdu5o5vXfv9m1PwipcAXZaA5EsEmpuUpTwIiFBQmdYI8cuXy6hPXyFda7EmTMSodZ+zoQ9\nRnsSWVkyw7tvX0e/xJkzIna+fAd17ChO/CNH6j/Sy0siTyQKCmTYXG0jKRRFCS3sZ12XlMiooeuu\n81391hFOmzdLKI+4ONflvOlJdO0qGe3s/RJ79oi/wxch16106FAtbL6s1wCRN09i3z6JMqnDXxUl\n/LD6JX74QfJdtGnju7q7dAE+/1wEyJ0/AvCuJ5GWJk7kV16p3u9rfwRQnUQowKYmIFJFQk1NihKe\nWEXi3Xd9a2oCqnsSP/7oeZKbtz2JxERHc5Ovh78CYopLTAyKSESeuUlHNilK+NK2rSQB2rABGDfO\nt3V36SICkZnpOVS6tSfB7L4Mc7VIdO4sUR7y8uSYr4e/Wvnss8CEeHci8kRCRzYpSvjSti3w8sti\nDnKew1Bf2rcXp/iwYZ4jpjZtKv6K3Fz3ZXJzZVhtYqLMiD73XBEHZv/0JAAJ1hgEM3pkioSamxQl\nPGnTBjh+HLj+et/XHRUlvQQjobtrywZn7UVYsY5wys4WH0UExY2LPJFQc5OihC9t2wLNmgFXXOGf\n+qdN85x3wkqPHtIjcEdWlmNQP6tI+KsXEUQiSyQKC2Xx5YgIRVECx5AhwIcfAk2a+Kf+efNcZ69z\n5qKLJIqrO9z1JPzljwgikTW6KTNThr8GKM56ONO5c2ccOHAg2M1QlBp06tQJvznnfgg0l1wC3Huv\nhPx2FScpK8sx8OC558r8iG7dRGAiiMgSCTU1GebAgQNgT6M3FCVIUCjMcerQQSwS337rOgptVpaj\n3yQhAWjZUrLR3X134NoZACLrk/vnn8WWqCiKUl8uvRT45BPXx5zNTYCYnAoLgd69/d+2AOJXkSCi\n9kS0kYj2ENFuIrrTTblniehXItpJRHUPTPLLL8DZZ9f5dEVRFBuXXuraL1FeLjkdOnRw3N+3r4ys\n9Jc/JUj4uydRCeAuZj4HwBAAtxORQyJaIroMQDdmPgvArQBerPPVVCQURfEVw4bJ5LtTpxz3Hzwo\nkV+d51oMHy7CEmH4VSSY+Rgz77SsnwGwF0A7p2JjAaRbymwDkEhE3g8yZhZzk4pE2NOlSxds3Lgx\n4NeNj48PvsNUCR0aNwZ+/3tg/XrH/a5MTYBMAHz66cC0LYDUKhJENMvIPgP1dAbQH4BTNnK0A2Af\nTesIagpJ7Zw8Kb+pqV6fqigAUFhYiM6+yl3gI/wlmOXl5bjxxhuRmJiItm3b4qmnnvJYfvny5ejc\nuTPi4+Mxbtw45OfnG67r1ltvRc+ePdGoUSOkp6f7/F78iiu/hPMciQjHSE9iqot907y5CBE1A/Au\ngFmWHoXvsZqaQmFkhBJyVFVVBbsJNTCbzUG79rx585CZmYlDhw5h48aNeOyxx7Bu3TqXZffs2YMZ\nM2bgjTfeQE5ODpo0aYLbbrvNcF39+/fHokWLcN555/n9vnyOVSTsRwK660lEKG5FgoiuJ6I1ALoQ\n0Wq7JQPAKXfnuagnCiIQrzPzBy6KHAFg7wFqb9lXg4ceesi2ZGRkOB785Rcd2RRhMDP+/e9/o3v3\n7mjRogUmTJiAPGsQNQDXXnst2rRpg+TkZIwYMQI//fST7dj06dMxc+ZMjB49GvHx8cjIyMD06dNx\nxx134IorrkBCQgKGDBmC/fv3284xmUzIysqyne+p7Lp169CzZ08kJyfj9ttvx4gRI/Df//7X4/0s\nXboUw4YNw1133YXU1FTMnz8fWVlZGDVqFFJTU9GyZUtMmjQJBQUFAIApU6bg4MGDGDNmDBISEvDE\nE08AAL7++mukpaUhOTkZAwYMwKZNm7x+tunp6Zg7dy4SEhLQs2dP3HLLLXjttddcll2+fDmuvPJK\npKWlIS4uDg8//DDee+89FBUVGarrtttuwx/+8AfExsZ63c6g0727xHKyn30d4iKRkZHh8K6sN8zs\ncgHQCcBVV8OwAAAgAElEQVQIAFsBDLdbBgKIcneei3rSATzp4fjlAD6yrA8G8LWbcuyR++9nfvhh\nz2UUG7U+zyDSuXNn3rBhAz/99NM8ZMgQzs7O5vLycp4xYwZff/31tnJLlizhoqIiLi8v59mzZ3P/\n/v1tx6ZNm8ZJSUm8detWZmYuLS3ladOmcWpqKn/77bdsNpt54sSJDvWZTCbOzMy0ne+ubG5uLick\nJPCqVavYbDbzM888wzExMfzqq696vK/XXnuNo6KieOHChWw2m7m0tJT37dvH69ev54qKCs7NzeXh\nw4fz7NmzHZ7Fxo0bbdtHjhzhlJQU/uSTT5iZef369ZySksK5ubnMzDxz5kxOSkri5ORk2691vV+/\nfszMnJeXx0TEx48ft9W7cuVK7tu3r8t2jx07lh977DGHffHx8bxjxw6v6ho2bBgvXbrU4zNiDsG/\nzTvuYP7b35grKmR7wADm7duD2yYvsDxPQ+9rV4uRl3xTACbL+tkArgQQbahyIA2AGcBOAN8D2AHg\nUsgoplvsyj0PYB+AXQAGuqnL85MYN4757bfr9TAbErU9T+lf13+pC1aR6NWrl8MLMjs7m6Ojo9ls\nNtc4x/qyKigoYGZ5yU+dOtWhzLRp0/jmm2+2ba9du5Z79epl2yYiB5FwVzY9PZ2HDh3qUHeHDh0M\niUSnTp08llm1ahUPHDjQtm19FlYWLFjAU6ZMcTjnkksu4fT0dI/12nPo0CE2mUxcVlZm2/fZZ59x\nly5dXJYfNWoUv/TSSw772rVrx5s2bfKqrrAViV27mM8/nzklhXn6dOZmzZgtohwO1FckjMy4/gLA\nhUSUDGAdgG8AXAdgooFeyhYALua01yh3h4F2eEaHv/qUUJiMfeDAAVx11VUwWcKsMDOio6ORk5OD\nVq1aYc6cOXj33XeRm5sLIgIRITc3F/Hx8QCADs7j2AG0tktrGxcXhzNn3LvI3JXNzs6uUXf79u0N\n3ZPzecePH8esWbOwefNmnDlzBmazGc2bN3d7/oEDB/DOO+9gzZo1AOSZVFZWYqSRyKYWmjVrBgAo\nKChAqmWgx+nTp23PzVV5qwnMirW8t3WFJX37At98Axw4AKxaJdFkPfwbRRpGHNfEzMUAxgF4gZmv\nAXCOf5vlJVVVmkcigrCGZejYsSM+/vhjnDp1CqdOnUJeXh6KiorQpk0bLF++HGvWrMHGjRuRn5+P\n3377zb7X6VCPr2nTpg0OOaW3PHz4sKFznds0Z84cmEwm7NmzB/n5+Vi2bJnHe+jQoQOmTJni8EwK\nCwvxt7/9DYDY/+Pj45GQkOCwxMfH41xL4LmkpCS0adMGu+zyMu/atQvnnOP6v/U555zjUDYzMxMV\nFRU4++yzva4rrOnUCZg1C1i8uEENkDEkEkQ0BNJz+Miyr9beQUA5dAhISZEQw0rYY31JzpgxA3Pm\nzMFBS1z/EydOYPXq1QBkuGpsbCySk5NRVFSE+++/P2Axf0aPHo0ff/wRq1evhtlsxvPPP4+cnJw6\n1VVYWIhmzZohPj4eR44cweOPP+5wvHXr1jZnOgBMmjQJa9aswbp161BVVYXS0lJs2rQJ2dnZAIBF\nixahsLAQBQUFDkthYSF22zlfJ0+ejH/+85/Iz8/H3r178fLLL2P69Oku2zhx4kSsWbMGW7ZsQVFR\nEebOnYvx48ejadOmhuqqqKhAaWkpmBnl5eUoKyvTuGFhhBGR+AuA+wG8z8x7iKgrgM/92ywvUVNT\nRGF92c+aNQtXXnklLr74YiQmJmLo0KHYvn07ABn507FjR7Rr1w59+vTB0KFDDddb1+NWUlJSsGLF\nCtxzzz1ITU3F//73P5x//vl1Gr0zb948fPfdd0hKSsKYMWMwfvx4h+P33XcfHn74YTRv3hxPPvkk\n2rdvjw8++AD/+te/0KJFC3Tq1AlPPPGE10N858+fj65du6JTp04YOXIk7rvvPlxkF700Pj4eW7Zs\nAQD07t0bL774Im644Qa0bt0aJSUlWLhwoeG6Lr74YsTFxWHr1q249dZbERcXh82bN3v9rJTgQEYV\n3TLXwTpzOuAQEbtt68KFMkTtxbpH9GhoEJF+zfkIZkb79u2xfPlyDA9CovpIQ/82fYvleda5m21k\nxvW5RPQ9gD0AfiKi74gotAyOOkdCCTDr1q3D6dOnUVZWhkceeQQAMHjw4CC3SlF8jxFz00uQIH2d\nmLkjgLsBvOzfZnmJmpuUALN161Z069YNLVu2xEcffYQPPvgAsbGxNRzH1vWZM2cGu8mKUidqNTcR\n0S5m7lfbPn/j0dzUtauE9D3rrEA2KazRLr0Squjfpm+pr7nJyDyJLCJ6EMDrlu1JALI8lA8sZWVA\ndjYQYoHZFEVRIgEj5qYbAbQA8B6AlQBSLftCg8xMGb/sHNtdURRFqTe19iSYOQ+Ay4xyIYH6IxRF\nUfyGkdFNnxFRkt12MhG5yOkXJFQkFEVR/IYRc1MqM9syjFh6Fi391yQv+fVXdVgriqL4CSMiUUVE\nHa0bRNQJQOgMPTh8uGZCciWs0fSlihI6GBGJBwB8SUSvE9EySFTY+/3bLC84fFiSkitKPdH0pe7x\nlL50xYoVSEtLQ9OmTb2KRquEB7WKBDN/Akk09DaAtwCcx8yh45M4cgQwGKZZabho+lJHfJm+NCUl\nBbNnz8b994fOt6PiQ+qTjCKQC1wlIikuZo6NZa6qcpFqQ/GEy+cZIlgT7VRVVfGjjz7K3bp149TU\nVL7uuuv41KlTtnLXXHMNt27dmpOSknj48OG8Z88e27Fp06bxbbfdxpdffjk3a9aMN2zYwNOmTePb\nb7+dR48ezfHx8Tx48GDOysqyneOcdMhT2U8//ZR79OjBSUlJPHPmTB4+fLihpENpaWk8e/ZsTklJ\n4QcffJAzMzN55MiRnJKSwi1atOCJEyfy6dOnmZl58uTJbDKZOC4ujuPj4/nxxx9nZuatW7fy0KFD\nOSkpifv3788ZGRleP+O2bdvy+vXrbdtz5851yNJnz5w5c3jixIm27czMTI6JieEzZ844lHvllVf4\nD3/4g9dtcSaU/zbDEdQz6ZARc1PocuQI0LZtg4rt3pB49tlnsXr1amzevBnZ2dm2fNJWLr/8cmRm\nZuL48eMYOHAgJk50zIP15ptv4sEHH0RhYSHS0tIAAG+//Tbmz5+P/Px8dOvWDQ888ICtvHMUWHdl\nT548iWuuuQYLFizAyZMn0aNHD2zdutXQPW3btg3du3fH8ePH8cADD4CZMWfOHBw7dgx79+7F4cOH\nbXmJ09PT0bFjR3z44YcoKCjAX//6V2RnZ+OKK67A3LlzkZeXhyeeeALjx4/HyZMnAQC33347kpOT\n0bx5c9uvdb1///4AgPz8fBw9ehR9+/a1tatfv37Ys2ePyzbv2bMH/fpVB1jo2rUrYmNj8csvvxi6\nZyW8cTtPgoi6MPN+d8dDgiNH1B/hJ2i+b4SX59V9jMNLL72EhQsXok2bNgCAuXPnolOnTli2bBlM\nJhOmTZtmKzt37lw8/fTTKCwstGVFGzt2rC3onjWM91VXXYXzzjsPgORJuPvuu6vb6hQKwl3ZtWvX\nok+fPhg7diwA4M4778QTTzxh6J7atWtni+MUGxuLbt26oVu3bgCqzTb/+Mc/HM6xb9eyZcswevRo\nXHLJJQCAUaNG4fzzz8fatWsxefJkLFy40CGMtyvOnDkDIkJiYqJtX0JCAgoLC92Wty9bW3klsvA0\nme5dAOcR0QZmHhWoBnnF4cPqj/AT9Xm5+wpNX1qTUEtfqkQ+nsxNJiKaA+BsIrrLeQlUAz2iPYmI\nRNOXhk/6UiXy8SQSEwCYIb2NeBdL8FGRiEisL0lNXxoe6UurqqpQVlaGiooKmM1mlJWVobKysk7P\nQwk93IoEM//MzAsA3MjM852XALbRPSoSEYmmL60mHNKXvv7662jSpAluv/12fPnll4iLi8Mtt9zi\n9bNQQhMj+SQSAcwD8HvLrk0A/sHMp/3cNud2cI22Dh4M/Oc/gGXkimIcjdnvO1jTl/oU/dv0LX5P\nXwrgvwAKAVxrWQoALKnrBX2KTqRTgoSmL1UaCkZEohszz2PmLMsyH0BXfzesVsxmICcHsAyPVJRA\noulLlYaCEXPTVgD3MPOXlu00AE8w85AAtM++HY7mpqNHgf79RSgUr9EuvRKq6N+mbwlE+tIZANIt\nvgkAyAMwta4X9Bka2E9RFMXvGMlMtwtAPyJKsGwX1HJKYFB/hKIoit8x0pMAEELiYEWHvyqKovid\n8A3wpyKhKIrid1QkFEVRFLfUKhJENM7FMoqIgpvnWoP7RSyavlRRQgcjPYmbALwCYKJleRnAvQC2\nENFkP7bNM9qTUHyMpi91zbFjxzB27Fi0a9cOJpPJFktLaRgYEYkoAL2YeTwzjwfQGwADGAQRi+Cg\nIqF4gaYvdcSb9KUmkwmXXXYZ3nvvvYAFUVRCByMi0YGZ7WesHbfsOwWgwj/NqoWCAoAZSEgIyuWV\nwMDM+Pe//43u3bujRYsWmDBhAvLy8mzHr732WrRp0wbJyckYMWIEfvrpJ9ux6dOnY+bMmRg9ejTi\n4+ORkZGB6dOn44477sAVV1yBhIQEDBkyBPv3V+fVMplMtoirtZVdt24devbsacuWN2LECPz3v//1\neD9Lly7FsGHDcNdddyE1NRXz589HVlYWRo0ahdTUVLRs2RKTJk2y5W6YMmUKDh48iDFjxiAhIcGW\n2Ojrr79GWloakpOTMWDAAGzatMnrZ5ueno65c+ciISEBPXv2xC233ILXXnvNZdmWLVtixowZOP/8\n83WSW0OktvymAF4A8CFkAt1UAGss+5oC+Lw+uVO9WWCf93bPHuYePdxkdFWMgBDOI2zNcf3000/z\nkCFDODs7m8vLy3nGjBkOeZiXLFnCRUVFXF5ezrNnz+b+/fvbjk2bNo2TkpJ469atzMxcWlrK06ZN\n49TUVP7222/ZbDbzxIkTHeozmUwOOa7dlc3NzeWEhARetWoVm81mfuaZZzgmJsZQjuuoqCheuHAh\nm81mLi0t5X379vH69eu5oqKCc3Nzefjw4Tx79myHZ7Fx40bb9pEjRzglJYU/+eQTZmZev349p6Sk\ncG5uLjMzz5w5k5OSkjg5Odn2a13v168fMzPn5eUxEfHx48dt9a5cuZL79u3rsf2VlZVMRHzgwAGP\n5epLKP9thiOoZ45rIy9nAjAewFOW5WpYwnkYOPdVADkAfnBzfDiAfAA7LMvfPdRVfdfr1jGPHOnb\nJ9nACOX/iFaR6NWrl8MLMjs7m6Ojo9lsNtc4x/riKygoYGZ5yU+dOtWhzLRp0/jmm2+2ba9du5Z7\n9epl2yYiB5FwVzY9PZ2HDh3qUHeHDh0MiUSnTp08llm1ahUPHDjQtm19FlYWLFjAU6ZMcTjnkksu\n4fT0dI/12nPo0CE2mUxcVlZm2/fZZ59xly5dPJ6nIhGe1FckjMy4ZiL6EkA5xBex3XJhIywB8ByA\ndA9lvmDmKw3WJ6g/wv/4yvZcD/OEpi+tSTDSlyoNGyNDYK8FsB3Sg7gWwDYiutpI5SxBAfNqKeb9\n20hFwv9IN7P+Sx3Q9KWhlb5UadgYcVw/AOB3zDyVmacAuADAgz5swxAi2klEHxFRb0NnqEhENNaX\npKYvDY30pQBQVlaG0tJSAEBpaSnKysrqdL9K+GFEJEzMfNxu+6TB84zwHYCOzNwfwPMAVhk6SyfS\nRTSavrSaUEhfCgBNmjRBQkICiAg9e/ZEXFyc1/eqhCdG8kk8DqAvgDctu66DOKINzZEgok4A1jBz\nXwNl9wM4j2V4rfMxnjdvnmy89BJGzJuHETNmGGmC4gKN2e87mDV9qS/Rv836kZGRgYyMDNv2/Pnz\nwfXIJ1GrSAAAEY0HYE0kvZmZ3zd8AaLOEJE418WxVmyZg0FEFwB4h5k7u6mn2l/eujWwYwfQtq3R\nZihO6H/E+rFu3ToMGjQIjRs3xuOPP45FixYhKyurTr0JxRH92/QtgUg6BGZeCWClt5UT0XIAIwCk\nENFBAPMAxEiVvBjA1UR0G2RSXgmkl1JbY4DcXKBFC2+boyg+Y+vWrbjhhhtQUVGB3r17O6QvXbZs\nmc10xcwgIkyaNAkvvPBCkFutKN7jtidBRIWQIa81DkFe8gGd7mzrSZw5Iz0JD0MXldrRrzUlVNG/\nTd/it54EM4fmoOn8fCApKditUBRFaRCEXz4JFQlFUZSAEZ4ikZgY7FYoiqI0CMJTJLQnoSiKEhAM\njW4KKU6fVpHwAZ06ddLcAEpI0qlTp2A3QbEj/ERCexI+QdN0KopihPA0N6lPQlEUJSCEp0hoT0JR\nFCUgqEgoiqIobgk/kVDHtaIoSsAIP5HQnoSiKErACE+RUMe1oihKQAhPkdCehKIoSkBQkVAURVHc\nEl4iwSyOazU3KYqiBITwEonSUsBkAho3DnZLFEVRGgThJRLqtFYURQko4ScS6o9QFEUJGCoSiqIo\nilvCSyR0trWiKEpACS+R0J6EoihKQAk/kVDHtaIoSsAIP5HQnoSiKErAUJFQFEVR3BJeIqGOa0VR\nlIASXiKhPQlFUZSAEn4ioY5rRVGUgBF+IqE9CUVRlIChIqEoiqK4JbxEQh3XiqIoASW8REJ7Eoqi\nKAElvESiogJo0iTYrVAURWkwhJdIJCUBRMFuhaIoSoMh/ERCURRFCRgqEoqiKIpbVCQURVEUt/hV\nJIjoVSLKIaIfPJR5loh+JaKdRNTfY4U621pRFCWg+LsnsQTAJe4OEtFlALox81kAbgXwosfatCeh\nKIoSUPwqEsz8JYA8D0XGAki3lN0GIJGIWrktrSKhKIoSUILtk2gH4JDd9hHLPteoSCiKogSUqGA3\nwBse+uor4KGHAAAjRozAiBEjgtoeRVGUUCMjIwMZGRk+q4+Y2WeVubwAUScAa5i5r4tjLwL4nJnf\ntmz/D8BwZs5xUZY5PR2YPNmv7VUURYkkiAjMXOdZyIEwN5FlccVqAFMAgIgGA8h3JRA21NykKIoS\nUPxqbiKi5QBGAEghooMA5gGIAcDMvJiZ1xLR5US0D0ARgOkeK1SRUBRFCSh+Nzf5CiJi/uEH4Nxz\ng90URVGUsCEczE2+Q3sSiqIoASW8REJnXCuKogSU8BKJZs2C3QJFUZQGRXiJhCm8mqsoihLu6FtX\nURRFcYuKhKIoiuIWFQlFURTFLSoSiqIoiltUJBRFURS3hFUU2MceY0RFEaKigEaNYPu1Lvbbzsdc\nLSaTsWOu1k2mmvtNJoDqPK9RURQl9AgrkZhT3Bhx3Bpx5tZoXNUKTSpbIdayxFS0REx5K0SXt0RU\nWQs0Km8Oc2UjmM1wu1RVGdtvv11VVb04nweISBgRlvruq+853h5zte3uevU9x0jb6lKutnapyCtK\nTcIqdlNxeTFyinJwtPAocopykHMmBzlFOThedLz690wOThSfQEFZAZIbJ6NF0xZoEdfC9psal2r7\nTY1LRUpcivw2SUFcdByoHm8J5mrxcPdrNks553X7cp7OcVfO03VdrXuqz7l9zu3wVLenOtzdl/05\ndS3n7j5cbbu7X2YRCaOC4o34+Lusfbu9qTeUF1f/Ft6c59zDr63+SP1AqG/sprASCW/aWllVidzi\nXJwoOoETxSdwougEcotzbcuJ4hM4WXLStn2y+CSquAopcSlIaZKClLgUNG/SHClN5Ne6JDdOlt8m\nybb1ZjHN6iUuSmhgFRFPYuJOdDyJoiuBcyesRoTQXTlv6rP/SKitnNH6/FHO1b+HkTpcPQv7jwHn\nMtYPBFfC4UtBq63+Ro2MCVpt+xYsANq0kb9rFQkfUlJRgpMlJ3Gy+CROlZxyWLdu55XmIa8kD6dK\nTtnWy8xlSGqchKTGSUhunOxyPalxEhIbJ8pvbKLDetOYpjCRya/3piiKe+w/EJzFxH7bk1A5n+du\n3ZNY2QtabYLprhwzMHZsdag7FYkQoNxcjvzSfOSX5iOvJA95pXm2betyuvQ08suq10+Xnbb9llSU\noFlMMyQ2TkRibCISYhOQEJuAxMaJSIiR9fjYeNv++Jh4h33xMfGIj41HfEw8ohtFB/txKIoSQqhI\nRADmKjMKygpwuuy0/FrEo7Cs0Lbful5QXoCCsgLbdmF5IQrLCm2/UaYoxMfGo1lMM8THWH6dtl0t\nTaObomlMU9t6s5hmaBrTFE2jm6JxVGM1pylKmKIiodhgZpRWluJM+RmbaDivW7eLyotwpvwMiiqK\nbNtFFZZ9dseKyotQUVWBuOg4m5A4/8ZFxyEuKs623jTasq+WpUl0E/mNaoKYRjEqRIriB1QkFL9T\nWVWJ4opinCk/g+KKYpuguFovrii2bVvXSypKbNvFFcUoqSyxlS+pLEFJRQnMbEaTqCYOwtEkugma\nRDWxCUrjqMay3+5Y46jGHtet5zSOalxjiY2KVV+QEvGoSCgRQWVVJUoqSmwCYl23Cox1vaSyBKWV\npQ7HSytLq9fNpQ7lrEtJRQnKzGW29dLKUpSZyxDTKKameDSKrSEmzsdiG8UiNirW9utwzG6/tX7n\n8rGN5Jj9uvakFH+gIqEodaSKq1BWWYYycxnKKstsYmNdtwqJbd2y37rPem6NdUt9tf2Wm8tRZpbf\nCnMFohtFi3C4EBDrtm3dToTsz3G1eDpmvWZMoxhEm6Jd7rc/FmWKUjELM1QkFCUCYGabaDgLiHXb\neZ913XassgwVVRUO69ZyFeYKlFe5L1dhrrCVsx6zipdtvaoClVWVNsGIbhTtUliiTdG2Y877HNZN\nMQ7l6vobZYpy2BdliqpRzrrPvmxDMTWqSCiKEjCquMpBSKwiYhUaT+vujhn6dXOssqrS8D7n/QRy\nKSJWIXEWFlfb9ovtfHJdl3PZRtTIfR0GF1d1RJmi0KpZK0SZJOqSioSiKEodMFeZbb0jq3DYxMSF\nsNhv25czs9lBnNzVYa4yO9RnZrNDG5zLuTrP1br1+mauPu+LaV+gW/NuAOovEmEV4E9RFMVXNDI1\nQiNTo2A3I+RpGEY5RVEUpU6oSCiKoihuUZFQFEVR3KIioSiKorhFRUJRFEVxi4qEoiiK4hYVCUVR\nFMUtKhKKoiiKW1QkFEVRFLeoSCiKoihuUZFQFEVR3OJ3kSCiS4nof0T0CxHd6+L4cCLKJ6IdluXv\n/m6ToiiKYgy/igQRmQA8D+ASAOcAuJ6Ieroo+gUzD7Qs//RnmyKBjIyMYDchZNBnUY0+i2r0WfgO\nf/ckLgDwKzMfYOYKAG8BGOuinKa68gL9D1CNPotq9FlUo8/Cd/hbJNoBOGS3fdiyz5khRLSTiD4i\not5+bpOiKIpikFDIJ/EdgI7MXExElwFYBeDsILdJURRFgZ8z0xHRYAAPMfOllu37ADAzL/Bwzn4A\n5zHzKaf9mpZOURSlDoRyZrpvAHQnok4AjgKYAOB6+wJE1IqZcyzrF0CE65RzRfW5SUVRFKVu+FUk\nmNlMRHcAWAfxf7zKzHuJ6FY5zIsBXE1EtwGoAFAC4Dp/tklRFEUxjl/NTYqiKEp4ExYzrmubkBfJ\nEFF7ItpIRHuIaDcR3WnZn0xE64joZyL6lIgSg93WQEBEJsuky9WW7Yb6HBKJaAUR7bX8bQxqwM9i\nNhH9SEQ/ENEbRBTTkJ4FEb1KRDlE9IPdPrf3T0T3E9Gvlr+di2urP+RFwosJeZFKJYC7mPkcAEMA\n3G65//sArGfmHgA2Arg/iG0MJLMA/GS33VCfwzMA1jJzLwD9APwPDfBZEFFbAP8HYCAz94WY0K9H\nw3oWSyDvR3tc3r9lisG1AHoBuAzAC0Tk0d8b8iIB4xPyIhJmPsbMOy3rZwDsBdAe8gyWWootBfCn\n4LQwcBBRewCXA3jFbndDfA4JAC5k5iUAwMyVzHwaDfBZWGgEoCkRRQFoAuAIGtCzYOYvAeQ57XZ3\n/1cCeMvyN/MbgF8h71i3hINIGJ2QF/EQUWcA/QF8DcA2KoyZjwFoGbyWBYynANwDwN6R1hCfQxcA\nuUS0xGJ6W0xEcWiAz4KZswH8B8BBiDicZub1aIDPwomWbu7f+X16BLW8T8NBJBQARNQMwLsAZll6\nFM4jDiJ6BAIRjQaQY+lVeeoeR/RzsBAFYCCAhcw8EEARxLzQoP4mAICIkiBfzZ0AtIX0KCaiAT6L\nWqjz/YeDSBwB0NFuu71lX4PB0o1+F8DrzPyBZXcOEbWyHG8N4Hiw2hcg0gBcSURZAN4EMJKIXgdw\nrIE9B0B604eY+VvL9kqIaDS0vwkA+COALGY+xcxmAO8DGIqG+SzscXf/RwB0sCtX6/s0HETCNiGP\niGIgE/JWB7lNgea/AH5i5mfs9q0GMM2yPhXAB84nRRLMPIeZOzJzV8jfwEZmngxgDRrQcwAAixnh\nEBFZw9eMArAHDexvwsJBAIOJqLHFATsKMrChoT0LgmMP2939rwYwwTICrAuA7gC2e6w4HOZJENGl\nkNEc1gl5/w5ykwIGEaUB+ALAbkiXkQHMgfzDvgP5KjgA4Fpmzg9WOwMJEQ0HcDczX0lEzdEAnwMR\n9YM48KMBZAGYDnHgNsRnMQ/y4VAB4HsAfwYQjwbyLIhoOYARAFIA5ACYB4mBtwIu7p+I7gdwE+R5\nzWLmdR7rDweRUBRFUYJDOJibFEVRlCChIqEoiqK4RUVCURRFcYuKhKIoiuIWFQlFURTFLSoSiqIo\niltUJBQlABDRcCJaE+x2KIq3qEgoSuDQSUlK2KEioSh2ENFEItpmia66yJLkqJCInrQktvmMiFIs\nZfsT0VYi2klEK62JXYiom6XcTiL61hL+AADi7RIFvR60m1QUL1CRUBQLlmRO1wEYaomuWgVgIoA4\nANuZuQ8kRMo8yylLAdzDzP0B/Gi3/w0Az1n2DwVw1LK/P4A7AfQG0I2Ihvr/rhSlfkQFuwGKEkKM\ngkRT/cYSLK4xJBZOFSQOEAAsA7DSkvgn0ZLwBRDBeMcS0r0dM68GAGYuBwBL8q/tzHzUsr0TQGcA\nX3g3ZlIAAADsSURBVAXgvhSlzqhIKEo1BGApMz/gsJPoQadybFfeG8rs1s3Q/39KGKDmJkWpZgOA\nq4moBWBLJt8REl31akuZiQC+ZOYCAKcsUXoBYDKATZaEUIeIaKyljhgiahLQu1AUH6JfMopigZn3\nEtHfAawjIhOAcgB3QDK/XWDpUeRA/BaAxOl/ySIC1nDdgAjGYiL6h6WOa1xdzn93oii+Q0OFK0ot\nEFEhM8cHux2KEgzU3KQotaNfUkqDRXsSiqIoilu0J6EoiqK4RUVCURRFcYuKhKIoiuIWFQlFURTF\nLSoSiqIoiltUJBRFURS3/D9pKUoTDrvMXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6b53748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize results\n",
    "epochs = np.arange(len(costs_0))\n",
    "plt.plot(epochs, np.log(costs_0), label='learning_rate=0.001') # Use log cost to see clearer\n",
    "plt.plot(epochs, np.log(costs_1), label='learning_rate=0.01')\n",
    "plt.plot(epochs, np.log(costs_2), label='learning_rate=0.1')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('log of cost')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bình luận về đồ thị kết quả: TODO\n",
    "- Với learning_rate là 0.1, dễ thấy đường biểu diễn chi phí theo số lần huấn luyện (epoch) là các đoạn gấp khúc, hỗn loạn, nhảy vọt từ chi phí 1.0 lên > 2.5 chỉ sau vài epoch và sau đó lên xuống thất thường với epoch tăng dần. Nhưng nhìn chung, chi phí luôn dao động > 2.0, đôi lúc chạm đến 3.0. Do đó, learning_rate này không khả quan.\n",
    "- Với learning_rate là 0.001 và 0.01, đường chi phí giảm dần theo số lần huấn luyện (epoch), mức độ giảm cũng giảm dần theo độ tăng epoch. Tuy nhiên, nhìn chung, 2 learning_rate này cho kết quả khả quan với chi phí thấp (cost < 1.0). Trong đó, learning_rate = 0.01 cho kết quả tốt hơn cả.\n",
    "- Tóm lại, learning_rate = 0.01 cho kết quả tốt nhất. Điều đó cho thấy, giá trị khả quan của learning_rate nằm ở một đoạn nhất định, không phải là quá lớn hay quá nhỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Chọn `W_1` ứng với `learning_rate` tốt nhất ở trên là bộ tham số của hàm dự đoán cuối cùng; đánh giá hàm dự đoán này bằng cách tính độ lỗi trên tập kiểm tra (ngoài ra, bạn cũng cho in ra độ lỗi trên tập huấn luyện)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 67.357%\n",
      "Test error: 67.760%\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "training_err = errs_1[-1]\n",
    "test_out = compute_softmax_output(W_1, test_X)\n",
    "test_err = sum([int(np.argmax(y_out)) != y[0] for y_out, y in zip(test_out, test_Y)]) * 100.0 / len(test_Y)\n",
    "\n",
    "print 'Training error: %.3f%%' % (training_err)\n",
    "print 'Test error: %.3f%%' % (test_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả chạy của mình: `Training err 67.357%, test err 67.760%`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "151px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "367px",
    "left": "0px",
    "right": "866.2px",
    "top": "106px",
    "width": "158px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
